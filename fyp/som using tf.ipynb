{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f702a468",
   "metadata": {},
   "source": [
    "Som\n",
    "https://notebook.community/tcstewar/testing_notebooks/som/Self%20Organizing%20Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0896163",
   "metadata": {},
   "source": [
    "### save as requirements.txt and run pip install -r requirements.txt\n",
    "\n",
    "matplotlib\n",
    "numpy\n",
    "nengo\n",
    "pandas\n",
    "tensorflow == 1.15.0\n",
    "pathlib\n",
    "logging\n",
    "sklearn\n",
    "scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3159ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nengo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80e13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(0,1, (100,3))\n",
    "# data = pd.read_excel(\"CM1.xlsx\", engine=\"openpyxl\")\n",
    "# data.drop(data.columns[len(data.columns) - 1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4bd2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfOrganizingMap(nengo.Process):\n",
    "    def __init__(self, weights, learning_rate=1e1, influence_sigma=1.5):\n",
    "        self.weights = weights\n",
    "        self.learning_rate = learning_rate\n",
    "        self.influence_sigma = influence_sigma\n",
    "\n",
    "        super().__init__(default_size_in=weights.shape[2],\n",
    "                         default_size_out=weights.shape[0]*weights.shape[1])\n",
    "    def make_step(self, shape_in, shape_out, dt, rng, state=None):\n",
    "        # this called during the build process, so any computationally expensive\n",
    "        #  pre-processing should be done here.  There isn't really much for an SOM,\n",
    "        #  but we can pre-generate the distance matrix to speed that part up\n",
    "\n",
    "        pos = np.array(np.meshgrid(np.arange(self.weights.shape[1]),\n",
    "                                   np.arange(self.weights.shape[0])))\n",
    "\n",
    "        def step_som(t, x, w=self.weights, pos=pos,\n",
    "                     sigma=self.influence_sigma,\n",
    "                     learning_rate=self.learning_rate):\n",
    "            # this will be called every timestep, with x as the current input\n",
    "\n",
    "            # first, find the closest element in the map\n",
    "            diff = np.sum((w - x[None,None,:])**2, axis=2)\n",
    "            best = np.argmin(diff)\n",
    "            best = np.array([best % diff.shape[1], best // diff.shape[1]])\n",
    "            #assert diff[best[1],best[0]] == np.min(diff)\n",
    "\n",
    "            # now compute how much to influence the elements\n",
    "            dist = np.sum((pos - best[:,None,None])**2, axis=0)\n",
    "            influence = np.exp(-dist/(2*sigma**2))\n",
    "\n",
    "            # update the weights\n",
    "            w += learning_rate * dt * influence[:,:,None] * (x - w)\n",
    "\n",
    "            # the output from the map every timestep will just be the influence\n",
    "            return influence.flatten()\n",
    "\n",
    "        return step_som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf68dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x170252a95c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = np.random.uniform(0, 1, (10, 12, 3))\n",
    "plt.imshow(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8674359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwcha\\Anaconda3\\lib\\site-packages\\nengo\\cache.py:613: UserWarning: Decoder cache could not acquire lock and was deactivated.\n",
      "  warnings.warn(\"Decoder cache could not acquire lock and was deactivated.\")\n"
     ]
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {},
       "tagName": "div"
      },
      "text/html": [
       "\n",
       "                <script>\n",
       "                    if (Jupyter.version.split(\".\")[0] < 5) {\n",
       "                        var pb = document.getElementById(\"9324988e-7d94-4349-884c-d3245e8f37b3\");\n",
       "                        var text = document.createTextNode(\n",
       "                            \"HMTL progress bar requires Jupyter Notebook >= \" +\n",
       "                            \"5.0 or Jupyter Lab. Alternatively, you can use \" +\n",
       "                            \"TerminalProgressBar().\");\n",
       "                        pb.parentNode.insertBefore(text, pb);\n",
       "                    }\n",
       "                </script>\n",
       "                <div id=\"9324988e-7d94-4349-884c-d3245e8f37b3\" style=\"\n",
       "                    width: 100%;\n",
       "                    border: 1px solid #cfcfcf;\n",
       "                    border-radius: 4px;\n",
       "                    text-align: center;\n",
       "                    position: relative;\">\n",
       "                  <div class=\"pb-text\" style=\"\n",
       "                      position: absolute;\n",
       "                      width: 100%;\">\n",
       "                    0%\n",
       "                  </div>\n",
       "                  <div class=\"pb-fill\" style=\"\n",
       "                      background-color: #bdd2e6;\n",
       "                      width: 0%;\">\n",
       "                    <style type=\"text/css\" scoped=\"scoped\">\n",
       "                        @keyframes pb-fill-anim {\n",
       "                            0% { background-position: 0 0; }\n",
       "                            100% { background-position: 100px 0; }\n",
       "                        }\n",
       "                    </style>\n",
       "                    &nbsp;\n",
       "                  </div>\n",
       "                </div>"
      ],
      "text/plain": [
       "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc['progress']['progress_bar'] = 'nengo.utils.progress.TerminalProgressBar'`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {
        "id": "b89a158f-885a-4e6c-92f4-b10edf93fa2c",
        "style": {
         "border": "1px solid #cfcfcf",
         "borderRadius": "4px",
         "boxSizing": "border-box",
         "position": "relative",
         "textAlign": "center",
         "width": "100%"
        }
       },
       "children": [
        {
         "attributes": {
          "class": "pb-text",
          "style": {
           "position": "absolute",
           "width": "100%"
          }
         },
         "children": [
          "Build finished in 0:00:01."
         ],
         "tagName": "div"
        },
        {
         "attributes": {
          "class": "pb-fill",
          "style": {
           "animation": "none",
           "backgroundColor": "#bdd2e6",
           "backgroundImage": "none",
           "backgroundSize": "100px 100%",
           "width": "100%"
          }
         },
         "children": [
          {
           "attributes": {
            "scoped": "scoped",
            "type": "text/css"
           },
           "children": [
            "\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }}"
           ],
           "tagName": "style"
          },
          " "
         ],
         "tagName": "div"
        }
       ],
       "tagName": "div"
      },
      "text/html": [
       "<script>\n",
       "              (function () {\n",
       "                  var root = document.getElementById('9324988e-7d94-4349-884c-d3245e8f37b3');\n",
       "                  var text = root.getElementsByClassName('pb-text')[0];\n",
       "                  var fill = root.getElementsByClassName('pb-fill')[0];\n",
       "\n",
       "                  text.innerHTML = 'Build finished in 0:00:01.';\n",
       "                  \n",
       "            fill.style.width = '100%';\n",
       "            fill.style.animation = 'pb-fill-anim 2s linear infinite';\n",
       "            fill.style.backgroundSize = '100px 100%';\n",
       "            fill.style.backgroundImage = 'repeating-linear-gradient(' +\n",
       "                '90deg, #bdd2e6, #edf2f8 40%, #bdd2e6 80%, #bdd2e6)';\n",
       "        \n",
       "                  \n",
       "                fill.style.animation = 'none';\n",
       "                fill.style.backgroundImage = 'none';\n",
       "            \n",
       "              })();\n",
       "        </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {},
       "tagName": "div"
      },
      "text/html": [
       "\n",
       "                <script>\n",
       "                    if (Jupyter.version.split(\".\")[0] < 5) {\n",
       "                        var pb = document.getElementById(\"e1f02e56-b5df-468d-b8cc-5f0feae18753\");\n",
       "                        var text = document.createTextNode(\n",
       "                            \"HMTL progress bar requires Jupyter Notebook >= \" +\n",
       "                            \"5.0 or Jupyter Lab. Alternatively, you can use \" +\n",
       "                            \"TerminalProgressBar().\");\n",
       "                        pb.parentNode.insertBefore(text, pb);\n",
       "                    }\n",
       "                </script>\n",
       "                <div id=\"e1f02e56-b5df-468d-b8cc-5f0feae18753\" style=\"\n",
       "                    width: 100%;\n",
       "                    border: 1px solid #cfcfcf;\n",
       "                    border-radius: 4px;\n",
       "                    text-align: center;\n",
       "                    position: relative;\">\n",
       "                  <div class=\"pb-text\" style=\"\n",
       "                      position: absolute;\n",
       "                      width: 100%;\">\n",
       "                    0%\n",
       "                  </div>\n",
       "                  <div class=\"pb-fill\" style=\"\n",
       "                      background-color: #bdd2e6;\n",
       "                      width: 0%;\">\n",
       "                    <style type=\"text/css\" scoped=\"scoped\">\n",
       "                        @keyframes pb-fill-anim {\n",
       "                            0% { background-position: 0 0; }\n",
       "                            100% { background-position: 100px 0; }\n",
       "                        }\n",
       "                    </style>\n",
       "                    &nbsp;\n",
       "                  </div>\n",
       "                </div>"
      ],
      "text/plain": [
       "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc['progress']['progress_bar'] = 'nengo.utils.progress.TerminalProgressBar'`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vdom.v1+json": {
       "attributes": {
        "id": "54c10863-c313-4be8-9074-3b2abb3cfe84",
        "style": {
         "border": "1px solid #cfcfcf",
         "borderRadius": "4px",
         "boxSizing": "border-box",
         "position": "relative",
         "textAlign": "center",
         "width": "100%"
        }
       },
       "children": [
        {
         "attributes": {
          "class": "pb-text",
          "style": {
           "position": "absolute",
           "width": "100%"
          }
         },
         "children": [
          "Simulation finished in 0:00:01."
         ],
         "tagName": "div"
        },
        {
         "attributes": {
          "class": "pb-fill",
          "style": {
           "animation": "none",
           "backgroundColor": "#bdd2e6",
           "backgroundImage": "none",
           "transition": "width 0.1s linear",
           "width": "100%"
          }
         },
         "children": [
          {
           "attributes": {
            "scoped": "scoped",
            "type": "text/css"
           },
           "children": [
            "\n                        @keyframes pb-fill-anim {\n                            0% { background-position: 0 0; }\n                            100% { background-position: 100px 0; }\n                        }}"
           ],
           "tagName": "style"
          },
          " "
         ],
         "tagName": "div"
        }
       ],
       "tagName": "div"
      },
      "text/html": [
       "<script>\n",
       "              (function () {\n",
       "                  var root = document.getElementById('e1f02e56-b5df-468d-b8cc-5f0feae18753');\n",
       "                  var text = root.getElementsByClassName('pb-text')[0];\n",
       "                  var fill = root.getElementsByClassName('pb-fill')[0];\n",
       "\n",
       "                  text.innerHTML = 'Simulation finished in 0:00:01.';\n",
       "                  \n",
       "            if (100.0 > 0.) {\n",
       "                fill.style.transition = 'width 0.1s linear';\n",
       "            } else {\n",
       "                fill.style.transition = 'none';\n",
       "            }\n",
       "\n",
       "            fill.style.width = '100.0%';\n",
       "            fill.style.animation = 'none';\n",
       "            fill.style.backgroundImage = 'none'\n",
       "        \n",
       "                  \n",
       "                fill.style.animation = 'none';\n",
       "                fill.style.backgroundImage = 'none';\n",
       "            \n",
       "              })();\n",
       "        </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nengo.Network()\n",
    "with model:\n",
    "    stim = nengo.Node(nengo.processes.PresentInput(data, presentation_time=0.001))\n",
    "\n",
    "    som = nengo.Node(SelfOrganizingMap(w))\n",
    "    nengo.Connection(stim, som, synapse=None)\n",
    "    p = nengo.Probe(som)\n",
    "\n",
    "sim = nengo.Simulator(model)\n",
    "sim.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95623180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x170264c9f48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f40928",
   "metadata": {},
   "source": [
    "https://github.com/cgorman/tensorflow-som/blob/master/tf_som.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa92559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5debd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfOrganizingMap:\n",
    "    \"\"\"\n",
    "    2-D rectangular grid planar Self-Organizing Map with Gaussian neighbourhood function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, m, n, dim, max_epochs=100, initial_radius=None, batch_size=128, initial_learning_rate=0.1,\n",
    "                 graph=None, std_coeff=0.5, model_name='Self-Organizing-Map', softmax_activity=False, gpus=0,\n",
    "                 output_sensitivity=-1.0, input_tensor=None, session=None, checkpoint_dir=None, restore_path=None):\n",
    "        \"\"\"\n",
    "        Initialize a self-organizing map on the tensorflow graph\n",
    "        :param m: Number of rows of neurons\n",
    "        :param n: Number of columns of neurons\n",
    "        :param dim: Dimensionality of the input data\n",
    "        :param max_epochs: Number of epochs to train for\n",
    "        :param initial_radius: Starting value of the neighborhood radius - defaults to max(m, n) / 2.0\n",
    "        :param batch_size: Number of input vectors to train on at a time\n",
    "        :param initial_learning_rate: The starting learning rate of the SOM. Decreases linearly w/r/t `max_epochs`\n",
    "        :param graph: The tensorflow graph to build the network on\n",
    "        :param std_coeff: Coefficient of the standard deviation of the neighborhood function\n",
    "        :param model_name: The name that will be given to the checkpoint files\n",
    "        :param softmax_activity: If `True` the activity will be softmaxed to form a probability distribution\n",
    "        :param gpus: The number of GPUs to train the SOM on\n",
    "        :param output_sensitivity The constant controlling the width of the activity gaussian. Numbers further from zero\n",
    "                elicit activity when distance is low, effectively introducing a threshold on the distance w/r/t activity.\n",
    "                See the plot in the readme file for a little introduction.\n",
    "        :param session: A `tf.Session()` for executing the graph\n",
    "        \"\"\"\n",
    "        self._m = abs(int(m))\n",
    "        self._n = abs(int(n))\n",
    "        self._dim = abs(int(dim))\n",
    "        if initial_radius is None:\n",
    "            self._initial_radius = max(m, n) / 2.0\n",
    "        else:\n",
    "            self._initial_radius = float(initial_radius)\n",
    "        self._max_epochs = abs(int(max_epochs))\n",
    "        self._batch_size = abs(int(batch_size))\n",
    "        self._std_coeff = abs(float(std_coeff))\n",
    "        self._softmax_activity = bool(softmax_activity)\n",
    "        self._model_name = str(model_name)\n",
    "        if output_sensitivity > 0:\n",
    "            output_sensitivity *= -1\n",
    "        elif output_sensitivity == 0:\n",
    "            output_sensitivity = -1\n",
    "        # The activity equation is kind of long so I'm naming this c for brevity\n",
    "        self._c = float(output_sensitivity)\n",
    "        self._sess = session\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._restore_path = restore_path\n",
    "        self._gpus = int(abs(gpus))\n",
    "        self._trained = False\n",
    "\n",
    "        # Initialized later, just declaring up here for neatness and to avoid warnings\n",
    "        self._weights = None\n",
    "        self._location_vects = None\n",
    "        self._input = None\n",
    "        self._epoch = None\n",
    "        self._training_op = None\n",
    "        self._centroid_grid = None\n",
    "        self._locations = None\n",
    "        self._activity_op = None\n",
    "        self._saver = None\n",
    "        self._merged = None\n",
    "        self._activity_merged = None\n",
    "        # This will be the collection of summaries for this subgraph. Add new summaries to it and pass it to merge()\n",
    "        self._summary_list = list()\n",
    "        self._input_tensor = input_tensor\n",
    "\n",
    "        if graph is None:\n",
    "            self._graph = tf.Graph()\n",
    "        elif type(graph) is not tf.Graph:\n",
    "            raise AttributeError('SOM graph input is not of type tf.Graph')\n",
    "        else:\n",
    "            self._graph = graph\n",
    "        self._initial_learning_rate = initial_learning_rate\n",
    "        # Create the ops and put them on the graph\n",
    "        self._initialize_tf_graph()\n",
    "        # If we want to reload from a save this will do that\n",
    "        self._maybe_reload_from_checkpoint()\n",
    "\n",
    "    def _save_checkpoint(self, global_step):\n",
    "        \"\"\" Save a checkpoint file\n",
    "        :param global_step: The current step of the network.\n",
    "        \"\"\"\n",
    "        if self._saver is None:\n",
    "            # Create the saver object\n",
    "            self._saver = tf.train.Saver()\n",
    "        if self._checkpoint_dir is not None:\n",
    "            output_name = Path(self._checkpoint_dir) / self._model_name\n",
    "            self._saver.save(self._sess, output_name, global_step=global_step)\n",
    "\n",
    "    def _maybe_reload_from_checkpoint(self):\n",
    "        \"\"\" If the program was called with a checkpoint argument, load the variables from that.\n",
    "        We are assuming that if it's loaded then it's already trained.\n",
    "        \"\"\"\n",
    "        if self._saver is None:\n",
    "            self._saver = tf.train.Saver()\n",
    "\n",
    "        if self._restore_path is not None:\n",
    "            logging.info(\"Restoring variables from checkpoint file {}\".format(\n",
    "                self._restore_path))\n",
    "            self._saver.restore(self._sess, Path(self._restore_path))\n",
    "            self._trained = True\n",
    "            logging.info(\"Checkpoint loaded\")\n",
    "\n",
    "    def _neuron_locations(self):\n",
    "        \"\"\" Maps an absolute neuron index to a 2d vector for calculating the neighborhood function \"\"\"\n",
    "        for i in range(self._m):\n",
    "            for j in range(self._n):\n",
    "                yield np.array([i, j])\n",
    "\n",
    "    def _initialize_tf_graph(self):\n",
    "        \"\"\" Initialize the SOM on the TensorFlow graph\n",
    "        In multi-gpu mode it will duplicate the model across the GPUs and use the CPU to calculate the final\n",
    "        weight updates.\n",
    "        \"\"\"\n",
    "        with self._graph.as_default(), tf.variable_scope(tf.get_variable_scope()), tf.device('/cpu:0'):\n",
    "            # This list will contain the handles to the numerator and denominator tensors for each of the towers\n",
    "            tower_updates = list()\n",
    "            # This is used by all of the towers and needs to be fed to the graph, so let's put it here\n",
    "            with tf.name_scope('Epoch'):\n",
    "                self._epoch = tf.placeholder(\"float\", [], name=\"iter\")\n",
    "            if self._gpus > 0:\n",
    "                for i in range(self._gpus):\n",
    "                    # We only want the summaries of the last tower, so wipe it out each time\n",
    "                    self._summary_list = list()\n",
    "                    with tf.device('/gpu:{}'.format(i)):\n",
    "                        with tf.name_scope('Tower_{}'.format(i)) as scope:\n",
    "                            # Create the model on this tower and add the (numerator, denominator) tensors to the list\n",
    "                            tower_updates.append(self._tower_som())\n",
    "                            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                with tf.device('/gpu:{}'.format(self._gpus - 1)):\n",
    "                    # Put the activity op on the last GPU\n",
    "                    self._activity_op = self._make_activity_op(\n",
    "                        self._input_tensor)\n",
    "            else:\n",
    "                # Running CPU only\n",
    "                with tf.name_scope(\"Tower_0\") as scope:\n",
    "                    tower_updates.append(self._tower_som())\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    self._activity_op = self._make_activity_op(\n",
    "                        self._input_tensor)\n",
    "\n",
    "            with tf.name_scope(\"Weight_Update\"):\n",
    "                # Get the outputs\n",
    "                numerators, denominators = zip(*tower_updates)\n",
    "                # Add them up\n",
    "                numerators = tf.reduce_sum(tf.stack(numerators), axis=0)\n",
    "                denominators = tf.reduce_sum(tf.stack(denominators), axis=0)\n",
    "                # Divide them\n",
    "                new_weights = tf.divide(numerators, denominators)\n",
    "                # Assign them\n",
    "                self._training_op = tf.assign(self._weights, new_weights)\n",
    "\n",
    "    def _tower_som(self):\n",
    "        \"\"\" Build a single SOM tower on the TensorFlow graph \"\"\"\n",
    "        # Randomly initialized weights for all neurons, stored together\n",
    "        # as a matrix Variable of shape [num_neurons, input_dims]\n",
    "        with tf.name_scope('Weights'):\n",
    "            # Each tower will get its own copy of the weights variable. Since the towers are constructed sequentially,\n",
    "            # the handle to the Tensors will be different for each tower even if we reference \"self\"\n",
    "            self._weights = tf.get_variable(name='weights',\n",
    "                                            shape=[\n",
    "                                                self._m * self._n, self._dim],\n",
    "                                            initializer=tf.random_uniform_initializer(maxval=1))\n",
    "\n",
    "            with tf.name_scope('summaries'):\n",
    "                # All summary ops are added to a list and then the merge() function is called at the end of\n",
    "                # this method\n",
    "                mean = tf.reduce_mean(self._weights)\n",
    "                self._summary_list.append(tf.summary.scalar('mean', mean))\n",
    "                with tf.name_scope('stdev'):\n",
    "                    stdev = tf.sqrt(tf.reduce_mean(\n",
    "                        tf.squared_difference(self._weights, mean)))\n",
    "                self._summary_list.append(tf.summary.scalar('stdev', stdev))\n",
    "                self._summary_list.append(tf.summary.scalar(\n",
    "                    'max', tf.reduce_max(self._weights)))\n",
    "                self._summary_list.append(tf.summary.scalar(\n",
    "                    'min', tf.reduce_min(self._weights)))\n",
    "                self._summary_list.append(\n",
    "                    tf.summary.histogram('histogram', self._weights))\n",
    "\n",
    "        # Matrix of size [m*n, 2] for SOM grid locations of neurons.\n",
    "        # Maps an index to an (x,y) coordinate of a neuron in the map for calculating the neighborhood distance\n",
    "        self._location_vects = tf.constant(np.array(\n",
    "            list(self._neuron_locations())), name='Location_Vectors')\n",
    "\n",
    "        with tf.name_scope('Input'):\n",
    "            self._input = tf.identity(self._input_tensor)\n",
    "\n",
    "        # Start by computing the best matching units / winning units for each input vector in the batch.\n",
    "        # Basically calculates the Euclidean distance between every\n",
    "        # neuron's weight vector and the inputs, and returns the index of the neurons which give the least value\n",
    "        # Since we are doing batch processing of the input, we need to calculate a BMU for each of the individual\n",
    "        # inputs in the batch. Will have the shape [batch_size]\n",
    "\n",
    "        # Oh also any time we call expand_dims it's almost always so we can make TF broadcast stuff properly\n",
    "        with tf.name_scope('BMU_Indices'):\n",
    "            # Distance between weights and the input vector\n",
    "            # Note we are reducing along 2nd axis so we end up with a tensor of [batch_size, num_neurons]\n",
    "            # corresponding to the distance between a particular input and each neuron in the map\n",
    "            # Also note we are getting the squared distance because there's no point calling sqrt or tf.norm\n",
    "            # if we're just doing a strict comparison\n",
    "            squared_distance = tf.reduce_sum(\n",
    "                tf.pow(tf.subtract(tf.expand_dims(self._weights, axis=0),\n",
    "                                   tf.expand_dims(self._input, axis=1)), 2), 2)\n",
    "\n",
    "            # Get the index of the minimum distance for each input item, shape will be [batch_size],\n",
    "            bmu_indices = tf.argmin(squared_distance, axis=1)\n",
    "\n",
    "        # This will extract the location of the BMU in the map for each input based on the BMU's indices\n",
    "        with tf.name_scope('BMU_Locations'):\n",
    "            # Using tf.gather we can use `bmu_indices` to index the location vectors directly\n",
    "            bmu_locs = tf.reshape(\n",
    "                tf.gather(self._location_vects, bmu_indices), [-1, 2])\n",
    "\n",
    "        with tf.name_scope('Learning_Rate'):\n",
    "            # With each epoch, the initial sigma value decreases linearly\n",
    "            radius = tf.subtract(self._initial_radius,\n",
    "                                 tf.multiply(self._epoch,\n",
    "                                             tf.divide(tf.cast(tf.subtract(self._initial_radius, 1),\n",
    "                                                               tf.float32),\n",
    "                                                       tf.cast(tf.subtract(self._max_epochs, 1),\n",
    "                                                               tf.float32))))\n",
    "\n",
    "            alpha = tf.multiply(self._initial_learning_rate,\n",
    "                                tf.subtract(1.0, tf.divide(tf.cast(self._epoch, tf.float32),\n",
    "                                                           tf.cast(self._max_epochs, tf.float32))))\n",
    "\n",
    "            # Construct the op that will generate a matrix with learning rates for all neurons and all inputs,\n",
    "            # based on iteration number and location to BMU\n",
    "\n",
    "            # Start by getting the squared difference between each BMU location and every other unit in the map\n",
    "            # bmu_locs is [batch_size, 2], i.e. the coordinates of the BMU for each input vector.\n",
    "            # location vects shape should be [1, num_neurons, 2]\n",
    "            # bmu_locs should be [batch_size, 1, 2]\n",
    "            # Output needs to be [batch_size, num_neurons], i.e. a row vector of distances for each input item\n",
    "            bmu_distance_squares = tf.reduce_sum(tf.pow(tf.subtract(\n",
    "                tf.expand_dims(self._location_vects, axis=0),\n",
    "                tf.expand_dims(bmu_locs, axis=1)), 2), 2)\n",
    "\n",
    "            # Using the distances between each BMU, construct the Gaussian neighborhood function.\n",
    "            # Basically, neurons which are close to the winner will move more than those further away.\n",
    "            # The radius tensor decreases the width of the Gaussian over time, so early in training more\n",
    "            # neurons will be affected by the winner and by the end of training only the winner will move.\n",
    "            # This tensor will be of shape [batch_size, num_neurons] as well and will be the value multiplied to\n",
    "            # each neuron based on its distance from the BMU for each input vector\n",
    "            neighbourhood_func = tf.exp(tf.divide(tf.negative(tf.cast(\n",
    "                bmu_distance_squares, \"float32\")), tf.multiply(\n",
    "                tf.square(tf.multiply(radius, self._std_coeff)), 2)))\n",
    "\n",
    "            # Finally multiply by the learning rate to decrease overall neuron movement over time\n",
    "            learning_rate_op = tf.multiply(neighbourhood_func, alpha)\n",
    "\n",
    "        # The batch formula for SOMs multiplies a neuron's neighborhood by all of the input vectors in the batch,\n",
    "        # then divides that by just the sum of the neighborhood function for each of the inputs.\n",
    "        # We are writing this in a way that performs that operation for each of the neurons in the map.\n",
    "        with tf.name_scope('Update_Weights'):\n",
    "            # The numerator needs to be shaped [num_neurons, dimensions] to represent the new weights\n",
    "            # for each of the neurons. At this point, the learning rate tensor will be\n",
    "            # shaped [batch_size, neurons].\n",
    "            # The end result is that, for each neuron in the network, we use the learning\n",
    "            # rate between it and each of the input vectors, to calculate a new set of weights.\n",
    "            numerator = tf.reduce_sum(tf.multiply(tf.expand_dims(learning_rate_op, axis=-1),\n",
    "                                                  tf.expand_dims(self._input, axis=1)), axis=0)\n",
    "\n",
    "            # The denominator is just the sum of the neighborhood functions for each neuron, so we get the sum\n",
    "            # along axis 1 giving us an output shape of [num_neurons]. We then expand the dims so we can\n",
    "            # broadcast for the division op. Again we transpose the learning rate tensor so it's\n",
    "            # [num_neurons, batch_size] representing the learning rate of each neuron for each input vector\n",
    "            denominator = tf.expand_dims(tf.reduce_sum(learning_rate_op,\n",
    "                                                       axis=0) + float(1e-12), axis=-1)\n",
    "\n",
    "        # We on;y really care about summaries from one of the tower SOMs, so assign the merge op to\n",
    "        # the last tower we make. Otherwise there's way too many on Tensorboard.\n",
    "        self._merged = tf.summary.merge(self._summary_list)\n",
    "\n",
    "        # With multi-gpu training we collect the results and do the weight assignment on the CPU\n",
    "        return numerator, denominator\n",
    "\n",
    "    def _make_activity_op(self, input_tensor):\n",
    "        \"\"\" Creates the op for calculating the activity of a SOM\n",
    "        :param input_tensor: A tensor to calculate the activity of. Must be of shape `[batch_size, dim]` where `dim` is\n",
    "        the dimensionality of the SOM's weights.\n",
    "        :return A handle to the newly created activity op:\n",
    "        \"\"\"\n",
    "        with self._graph.as_default():\n",
    "            with tf.name_scope(\"Activity\"):\n",
    "                # This constant controls the width of the gaussian.\n",
    "                # The closer to 0 it is, the wider it is.\n",
    "                c = tf.constant(self._c, dtype=\"float32\")\n",
    "                # Get the euclidean distance between each neuron and the input vectors\n",
    "                dist = tf.norm(tf.subtract(\n",
    "                    tf.expand_dims(self._weights, axis=0),\n",
    "                    tf.expand_dims(input_tensor, axis=1)),\n",
    "                    name=\"Distance\", axis=2)  # [batch_size, neurons]\n",
    "\n",
    "                # Calculate the Gaussian of the activity. Units with distances closer to 0 will have activities\n",
    "                # closer to 1.\n",
    "                activity = tf.exp(tf.multiply(\n",
    "                    tf.pow(dist, 2), c), name=\"Gaussian\")\n",
    "\n",
    "                # Convert the activity into a softmax probability distribution\n",
    "                if self._softmax_activity:\n",
    "                    activity = tf.divide(tf.exp(activity),\n",
    "                                         tf.expand_dims(tf.reduce_sum(\n",
    "                                             tf.exp(activity), axis=1), axis=-1),\n",
    "                                         name=\"Softmax\")\n",
    "\n",
    "                return tf.identity(activity, name=\"Output\")\n",
    "\n",
    "    def get_activity_op(self):\n",
    "        return self._activity_op\n",
    "\n",
    "    def train(self, num_inputs, writer=None, step_offset=0):\n",
    "        \"\"\" Train the network on the data provided by the input tensor.\n",
    "        :param num_inputs: The total number of inputs in the data-set. Used to determine batches per epoch\n",
    "        :param writer: The summary writer to add summaries to. This is created by the caller so when we stack layers\n",
    "                        we don't end up with duplicate outputs. If `None` then no summaries will be written.\n",
    "        :param step_offset: The offset for the global step variable so I don't accidentally overwrite my summaries\n",
    "        \"\"\"\n",
    "        # Divide by num_gpus to avoid accidentally training on the same data a bunch of times\n",
    "        if self._gpus > 0:\n",
    "            batches_per_epoch = num_inputs // self._batch_size // self._gpus\n",
    "        else:\n",
    "            batches_per_epoch = num_inputs // self._batch_size\n",
    "        total_batches = batches_per_epoch * self._max_epochs\n",
    "        # Get how many batches constitute roughly 10 percent of the total for recording summaries\n",
    "        summary_mod = int(0.1 * total_batches)\n",
    "        global_step = step_offset\n",
    "\n",
    "        logging.info(\"Training self-organizing Map\")\n",
    "        for epoch in range(self._max_epochs):\n",
    "            logging.info(\"Epoch: {}/{}\".format(epoch, self._max_epochs))\n",
    "            for batch in range(batches_per_epoch):\n",
    "                current_batch = batch + (batches_per_epoch * epoch)\n",
    "                global_step = current_batch + step_offset\n",
    "                percent_complete = current_batch / total_batches\n",
    "                logging.debug(\"\\tBatch {}/{} - {:.2%} complete\".format(batch,\n",
    "                                                                       batches_per_epoch, percent_complete))\n",
    "                # Only do summaries when a SummaryWriter has been provided\n",
    "                if writer:\n",
    "                    if current_batch > 0 and current_batch % summary_mod == 0:\n",
    "                        run_options = tf.RunOptions(\n",
    "                            trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                        run_metadata = tf.RunMetadata()\n",
    "                        summary, _, _, = self._sess.run([self._merged, self._training_op,\n",
    "                                                         self._activity_op],\n",
    "                                                        feed_dict={\n",
    "                                                            self._epoch: epoch},\n",
    "                                                        options=run_options,\n",
    "                                                        run_metadata=run_metadata)\n",
    "                        writer.add_run_metadata(\n",
    "                            run_metadata, \"step_{}\".format(global_step))\n",
    "                        writer.add_summary(summary, global_step)\n",
    "                        self._save_checkpoint(global_step)\n",
    "                    else:\n",
    "                        summary, _ = self._sess.run([self._merged, self._training_op],\n",
    "                                                    feed_dict={self._epoch: epoch})\n",
    "                        writer.add_summary(summary, global_step)\n",
    "                else:\n",
    "                    self._sess.run(self._training_op, feed_dict={\n",
    "                                   self._epoch: epoch})\n",
    "\n",
    "        self._trained = True\n",
    "        return global_step\n",
    "\n",
    "    @property\n",
    "    def output_weights(self):\n",
    "        \"\"\" :return: The weights of the trained SOM as a NumPy array, or `None` if the SOM hasn't been trained \"\"\"\n",
    "        if self._trained:\n",
    "            return np.array(self._sess.run(self._weights))\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad56de8",
   "metadata": {},
   "source": [
    "https://github.com/cgorman/tensorflow-som/blob/master/example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a50b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ef70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_umatrix(input_vects, weights, m, n):\n",
    "    \"\"\" Generates an n x m u-matrix of the SOM's weights and bmu indices of all the input data points\n",
    "    Used to visualize higher-dimensional data. Shows the average distance between a SOM unit and its neighbors.\n",
    "    When displayed, areas of a darker color separated by lighter colors correspond to clusters of units which\n",
    "    encode similar information.\n",
    "    :param weights: SOM weight matrix, `ndarray`\n",
    "    :param m: Rows of neurons\n",
    "    :param n: Columns of neurons\n",
    "    :return: m x n u-matrix `ndarray` \n",
    "    :return: input_size x 1 bmu indices 'ndarray'\n",
    "    \"\"\"\n",
    "    umatrix = np.zeros((m * n, 1))\n",
    "    # Get the location of the neurons on the map to figure out their neighbors. I know I already have this in the\n",
    "    # SOM code but I put it here too to make it easier to follow.\n",
    "    neuron_locs = list()\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            neuron_locs.append(np.array([i, j]))\n",
    "    # Get the map distance between each neuron (i.e. not the weight distance).\n",
    "    neuron_distmat = distance_matrix(neuron_locs, neuron_locs)\n",
    "\n",
    "    for i in range(m * n):\n",
    "        # Get the indices of the units which neighbor i\n",
    "        neighbor_idxs = neuron_distmat[i] <= 1  # Change this to `< 2` if you want to include diagonal neighbors\n",
    "        # Get the weights of those units\n",
    "        neighbor_weights = weights[neighbor_idxs]\n",
    "        # Get the average distance between unit i and all of its neighbors\n",
    "        # Expand dims to broadcast to each of the neighbors\n",
    "        umatrix[i] = distance_matrix(np.expand_dims(weights[i], 0), neighbor_weights).mean()\n",
    "\n",
    "    bmu_indices = []\n",
    "    for vect in input_vects:\n",
    "        min_index = min([i for i in range(len(list(weights)))],\n",
    "                        key=lambda x: np.linalg.norm(vect-\n",
    "                                                     list(weights)[x]))\n",
    "        bmu_indices.append(neuron_locs[min_index])\n",
    "        \n",
    "    return umatrix, bmu_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2606028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-1a972f2af552>:38: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 06:30:48,390 - WARNING - From <ipython-input-11-1a972f2af552>:38: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "2021-08-23 06:30:48,494 - INFO - Training self-organizing Map\n",
      "2021-08-23 06:30:48,495 - INFO - Epoch: 0/20\n",
      "2021-08-23 06:30:48,495 - DEBUG - \tBatch 0/3 - 0.00% complete\n",
      "2021-08-23 06:30:48,520 - DEBUG - \tBatch 1/3 - 1.67% complete\n",
      "2021-08-23 06:30:48,526 - DEBUG - \tBatch 2/3 - 3.33% complete\n",
      "2021-08-23 06:30:48,531 - INFO - Epoch: 1/20\n",
      "2021-08-23 06:30:48,532 - DEBUG - \tBatch 0/3 - 5.00% complete\n",
      "2021-08-23 06:30:48,537 - DEBUG - \tBatch 1/3 - 6.67% complete\n",
      "2021-08-23 06:30:48,542 - DEBUG - \tBatch 2/3 - 8.33% complete\n",
      "2021-08-23 06:30:48,547 - INFO - Epoch: 2/20\n",
      "2021-08-23 06:30:48,548 - DEBUG - \tBatch 0/3 - 10.00% complete\n",
      "2021-08-23 06:30:48,553 - DEBUG - \tBatch 1/3 - 11.67% complete\n",
      "2021-08-23 06:30:48,558 - DEBUG - \tBatch 2/3 - 13.33% complete\n",
      "2021-08-23 06:30:48,564 - INFO - Epoch: 3/20\n",
      "2021-08-23 06:30:48,564 - DEBUG - \tBatch 0/3 - 15.00% complete\n",
      "2021-08-23 06:30:48,569 - DEBUG - \tBatch 1/3 - 16.67% complete\n",
      "2021-08-23 06:30:48,574 - DEBUG - \tBatch 2/3 - 18.33% complete\n",
      "2021-08-23 06:30:48,580 - INFO - Epoch: 4/20\n",
      "2021-08-23 06:30:48,580 - DEBUG - \tBatch 0/3 - 20.00% complete\n",
      "2021-08-23 06:30:48,587 - DEBUG - \tBatch 1/3 - 21.67% complete\n",
      "2021-08-23 06:30:48,592 - DEBUG - \tBatch 2/3 - 23.33% complete\n",
      "2021-08-23 06:30:48,598 - INFO - Epoch: 5/20\n",
      "2021-08-23 06:30:48,598 - DEBUG - \tBatch 0/3 - 25.00% complete\n",
      "2021-08-23 06:30:48,604 - DEBUG - \tBatch 1/3 - 26.67% complete\n",
      "2021-08-23 06:30:48,609 - DEBUG - \tBatch 2/3 - 28.33% complete\n",
      "2021-08-23 06:30:48,615 - INFO - Epoch: 6/20\n",
      "2021-08-23 06:30:48,615 - DEBUG - \tBatch 0/3 - 30.00% complete\n",
      "2021-08-23 06:30:48,621 - DEBUG - \tBatch 1/3 - 31.67% complete\n",
      "2021-08-23 06:30:48,626 - DEBUG - \tBatch 2/3 - 33.33% complete\n",
      "2021-08-23 06:30:48,631 - INFO - Epoch: 7/20\n",
      "2021-08-23 06:30:48,632 - DEBUG - \tBatch 0/3 - 35.00% complete\n",
      "2021-08-23 06:30:48,637 - DEBUG - \tBatch 1/3 - 36.67% complete\n",
      "2021-08-23 06:30:48,642 - DEBUG - \tBatch 2/3 - 38.33% complete\n",
      "2021-08-23 06:30:48,648 - INFO - Epoch: 8/20\n",
      "2021-08-23 06:30:48,649 - DEBUG - \tBatch 0/3 - 40.00% complete\n",
      "2021-08-23 06:30:48,655 - DEBUG - \tBatch 1/3 - 41.67% complete\n",
      "2021-08-23 06:30:48,661 - DEBUG - \tBatch 2/3 - 43.33% complete\n",
      "2021-08-23 06:30:48,667 - INFO - Epoch: 9/20\n",
      "2021-08-23 06:30:48,667 - DEBUG - \tBatch 0/3 - 45.00% complete\n",
      "2021-08-23 06:30:48,673 - DEBUG - \tBatch 1/3 - 46.67% complete\n",
      "2021-08-23 06:30:48,678 - DEBUG - \tBatch 2/3 - 48.33% complete\n",
      "2021-08-23 06:30:48,684 - INFO - Epoch: 10/20\n",
      "2021-08-23 06:30:48,685 - DEBUG - \tBatch 0/3 - 50.00% complete\n",
      "2021-08-23 06:30:48,691 - DEBUG - \tBatch 1/3 - 51.67% complete\n",
      "2021-08-23 06:30:48,697 - DEBUG - \tBatch 2/3 - 53.33% complete\n",
      "2021-08-23 06:30:48,702 - INFO - Epoch: 11/20\n",
      "2021-08-23 06:30:48,703 - DEBUG - \tBatch 0/3 - 55.00% complete\n",
      "2021-08-23 06:30:48,708 - DEBUG - \tBatch 1/3 - 56.67% complete\n",
      "2021-08-23 06:30:48,714 - DEBUG - \tBatch 2/3 - 58.33% complete\n",
      "2021-08-23 06:30:48,719 - INFO - Epoch: 12/20\n",
      "2021-08-23 06:30:48,720 - DEBUG - \tBatch 0/3 - 60.00% complete\n",
      "2021-08-23 06:30:48,725 - DEBUG - \tBatch 1/3 - 61.67% complete\n",
      "2021-08-23 06:30:48,730 - DEBUG - \tBatch 2/3 - 63.33% complete\n",
      "2021-08-23 06:30:48,736 - INFO - Epoch: 13/20\n",
      "2021-08-23 06:30:48,736 - DEBUG - \tBatch 0/3 - 65.00% complete\n",
      "2021-08-23 06:30:48,741 - DEBUG - \tBatch 1/3 - 66.67% complete\n",
      "2021-08-23 06:30:48,747 - DEBUG - \tBatch 2/3 - 68.33% complete\n",
      "2021-08-23 06:30:48,752 - INFO - Epoch: 14/20\n",
      "2021-08-23 06:30:48,753 - DEBUG - \tBatch 0/3 - 70.00% complete\n",
      "2021-08-23 06:30:48,758 - DEBUG - \tBatch 1/3 - 71.67% complete\n",
      "2021-08-23 06:30:48,763 - DEBUG - \tBatch 2/3 - 73.33% complete\n",
      "2021-08-23 06:30:48,768 - INFO - Epoch: 15/20\n",
      "2021-08-23 06:30:48,768 - DEBUG - \tBatch 0/3 - 75.00% complete\n",
      "2021-08-23 06:30:48,773 - DEBUG - \tBatch 1/3 - 76.67% complete\n",
      "2021-08-23 06:30:48,779 - DEBUG - \tBatch 2/3 - 78.33% complete\n",
      "2021-08-23 06:30:48,784 - INFO - Epoch: 16/20\n",
      "2021-08-23 06:30:48,784 - DEBUG - \tBatch 0/3 - 80.00% complete\n",
      "2021-08-23 06:30:48,790 - DEBUG - \tBatch 1/3 - 81.67% complete\n",
      "2021-08-23 06:30:48,795 - DEBUG - \tBatch 2/3 - 83.33% complete\n",
      "2021-08-23 06:30:48,800 - INFO - Epoch: 17/20\n",
      "2021-08-23 06:30:48,801 - DEBUG - \tBatch 0/3 - 85.00% complete\n",
      "2021-08-23 06:30:48,805 - DEBUG - \tBatch 1/3 - 86.67% complete\n",
      "2021-08-23 06:30:48,811 - DEBUG - \tBatch 2/3 - 88.33% complete\n",
      "2021-08-23 06:30:48,816 - INFO - Epoch: 18/20\n",
      "2021-08-23 06:30:48,816 - DEBUG - \tBatch 0/3 - 90.00% complete\n",
      "2021-08-23 06:30:48,822 - DEBUG - \tBatch 1/3 - 91.67% complete\n",
      "2021-08-23 06:30:48,827 - DEBUG - \tBatch 2/3 - 93.33% complete\n",
      "2021-08-23 06:30:48,832 - INFO - Epoch: 19/20\n",
      "2021-08-23 06:30:48,833 - DEBUG - \tBatch 0/3 - 95.00% complete\n",
      "2021-08-23 06:30:48,838 - DEBUG - \tBatch 1/3 - 96.67% complete\n",
      "2021-08-23 06:30:48,843 - DEBUG - \tBatch 2/3 - 98.33% complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Make sure you allow_soft_placement, some ops have to be put on the CPU (e.g. summary operations)\n",
    "        session = tf.Session(config=tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=False))\n",
    "#       ori input for tf-som\n",
    "#         num_inputs = 1024\n",
    "#         dims = 40\n",
    "#         clusters = 2\n",
    "#         # Makes toy clusters with pretty clear separation, see the sklearn site for more info\n",
    "#         blob_data = make_blobs(num_inputs, dims, clusters)\n",
    "\n",
    "# cmi?\n",
    "#         df = pd.read_excel(\"CM1.xlsx\", engine=\"openpyxl\")\n",
    "#         df.drop(df.columns[len(df.columns) - 1], axis=1, inplace=True)\n",
    "#         blob_data=df.to_numpy()\n",
    "        ori_iris = np.genfromtxt('cm1.csv', skip_header=1,delimiter=',')\n",
    "        iris = np.delete(ori_iris, np.s_[-1:], axis=1)\n",
    "        np.set_printoptions(suppress=True)\n",
    "#         num_inputs = row of data(input), dims = \n",
    "        num_inputs = 504\n",
    "        dims = 40\n",
    "        clusters = 2\n",
    "        \n",
    "        # Scale the blob data for easier training. Also index 0 because the output is a (data, label) tuple.\n",
    "        scaler = StandardScaler()\n",
    "        input_data = scaler.fit_transform(iris)\n",
    "        batch_size = 128\n",
    "\n",
    "        # Build the TensorFlow dataset pipeline per the standard tutorial.\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(input_data.astype(np.float32))\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        # This is more neurons than you need but it makes the visualization look nicer\n",
    "        m = 20\n",
    "        n = 20\n",
    "\n",
    "        # Build the SOM object and place all of its ops on the graph\n",
    "        som = SelfOrganizingMap(m=m, n=n, dim=dims, max_epochs=20, gpus=1, session=session, graph=graph,\n",
    "                                input_tensor=next_element, batch_size=batch_size, initial_learning_rate=0.1)\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        session.run([init_op])\n",
    "\n",
    "        # Note that I don't pass a SummaryWriter because I don't really want to record summaries in this script\n",
    "        # If you want Tensorboard support just make a new SummaryWriter and pass it to this method\n",
    "        som.train(num_inputs=num_inputs)\n",
    "\n",
    "        weights = som.output_weights\n",
    "        \n",
    "        umatrix, bmu_loc = get_umatrix(input_data,weights, m, n)\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(umatrix.reshape((m, n)), origin='lower')\n",
    "        plt.show(block=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
